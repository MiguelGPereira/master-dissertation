getNonZeroIndexes <- function(cutp) {
out <- list()#vector("list", length(cutp))
outIndex <- 1
zeroRow <- list(numeric(0))
for (i in 1:length(cutp)) {
l <- cutp[i]
if (!identical(l, zeroRow)) {
out[outIndex] <- i
outIndex <- outIndex + 1
}
}
}
test <- getNonZeroIndexes(DISC$cutp)
test
getNonZeroIndexes <- function(cutp) {
out <- list()#vector("list", length(cutp))
outIndex <- 1
zeroRow <- list(numeric(0))
for (i in 1:length(cutp)) {
l <- cutp[i]
if (!identical(l, zeroRow)) {
out[outIndex] <- i
outIndex <- outIndex + 1
}
}
return(out)
}
test <- getNonZeroIndexes(DISC$cutp)
test
test2 <- test[test, ]
length(xs)
nrows(xs)
nrow(xs)
head(xsd)
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
xs <- x[-train_ind, ]
xs <- xs[c(1:6), ]
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
head(xsd)
xs <- x[-train_ind, ]
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
head(xsd)
xs <- xs[c(1:29), ]
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
head(xsd)
xs <- x[-train_ind, ]
xs <- xs[c(1:30), ]
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
head(xsd)
DISC$cutp
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[j], Inf))
})
head(xsd)
xs <- x[-train_ind, ]
xs <- xs[c(1:5), ]
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[j], Inf))
})
head(xsd)
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
head(xsd)
xs <- x[-train_ind, ]
View(xs)
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
xs <- xs[, 2]
head(xs)
xs <- x[-train_ind, ]
View(xs)
xs <- xs[, c(5:29)]
xs <- xs[, c(5,29)]
xs <- xs[, c(2,3)]
View(xsd)
xs <- x[-train_ind, ]
test
xs <- x[-train_ind, ]
xs <- xs[, c(1,2,3,4,5,7,8,10,12,16,17,26,27,28,29)]
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
head(xsd)
wut <- DISC$cutp[c(2,3)]
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, wut[[j]], Inf))
})
head(xsd)
xs <- x[-train_ind, ]
xs <- xs[, c(1,2,3,4,5,7,8,10,12,16,17,26,27,28,29)]
wut <- DISC$cutp[c(1,2,3,4,5,7,8,10,12,16,17,26,27,28,29)]
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, wut[[j]], Inf))
})
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, wut[j], Inf))
})
head(xsd)
xs <- xs[, c(1,2,3,4,5,7,8,10,12,16,17,26,27,28,29)]
xs <- x[-train_ind, ]
xs <- xs[, c(1,2,3,4,5,7,8,10,12,16,17,26,27,28,29)]
wut <- DISC$cutp[c(1,2,3,4,5,7,8,10,12,16,17,26,27,28,29)]
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, wut[j], Inf))
})
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, wut[[j]], Inf))
})
head(xsd)
xsd <- sapply(1:nrow(xs), function(j){
findInterval(xs[,j], c(-Inf, wut[[j]], Inf))
})
head(xsd)
xsd <- sapply(1:nrow(xs), function(j){
print(j)
findInterval(xs[,j], c(-Inf, wut[[j]], Inf))
})
xsd <- sapply(1:nrow(xs) - 1, function(j){
print(j)
findInterval(xs[,j], c(-Inf, wut[[j]], Inf))
})
xsd <- sapply(1:15, function(j){
print(j)
findInterval(xs[,j], c(-Inf, wut[[j]], Inf))
})
head(xsd)
xsd <- sapply(1:ncol(xs), function(j){
print(j)
findInterval(xs[,j], c(-Inf, wut[[j]], Inf))
})
head(xsd)
xsd <- sapply(1:ncol(xs), function(j){
findInterval(xs[,j], c(-Inf, wut[[j]], Inf))
})
head(xsd)
xs <- x[-train_ind, ]
xsd <- sapply(1:ncol(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
head(xsd)
print(c(1,2,3,4,5,7,8,10,12,16,17,26,27,28,29))
print(list(1,2,3,4,5,7,8,10,12,16,17,26,27,28,29))
getNonZeroIndexes <- function(cutp) {
out <- c()
outIndex <- 1
zeroRow <- list(numeric(0))
for (i in 1:length(cutp)) {
l <- cutp[i]
if (!identical(l, zeroRow)) {
out[outIndex] <- i
outIndex <- outIndex + 1
}
}
return(out)
}
test <- getNonZeroIndexes(DISC$cutp)
test
test2 <- xs[, test]
head(test2)
xsd <- sapply(1:ncol(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
yp <- crank(rulz, xsd, ys, std, m2, mt)
View(crank)
yp <- crank(rulz, xsd, ys, std, m2, 1)#mt)
tau <- mean(sapply(1:nrow(ys), function(j) cor(ys[j,], yp[,j], method="kendall")))
tau
# load dependencies
require("carenR")
source("LRAR/caren.R")
source("LRAR/predictLRAR.R")
source("edira/edira.R")
# read DATA
## PT
#out <- read.csv("../data/out_german_based.csv", sep = ";", stringsAsFactors=FALSE, fileEncoding="latin1")
## GET
out <- read.csv("../data/out_german.csv", sep = ";", stringsAsFactors=FALSE, fileEncoding="latin1")
# transform DATA
## select rows of relevant parties
### PT
#rankings <- out[,c(3,4,11,15,29)]
### GER
rankings <- out[,c(33:37)]
## split in independent variables (x) and votes (y)
### PT
#y <- t(apply(-rankings, 1, rank))
#x <- out[,-c(0:33)]
### GER
y <- t(apply(rankings, 1, rank))
x <- out[,c(4:32)]
## transform dataframes in matrixes
x <- as.matrix(x)
y <- as.matrix(y)
## sample size percentage for TRAIN
smp_size <- floor(0.75 * nrow(x))
## set the seed to make the partition reproductible
set.seed(123)
## split
train_ind <- sample(seq_len(nrow(x)), size = smp_size)
x <- x[train_ind, ]
xs <- x[-train_ind, ]
y <- y[train_ind, ]
ys <- y[-train_ind, ]
# discretize TRAIN
DISC <- mdlp.rank(x, y, method = "kendall")
xd = DISC$Disc.data
# mine LR rules
rulz <- aflrC7(xd, y, msup = 1, mconf = 70, mlift = 0, mimp = 0, theta = 0, Xmx = "2000M")
getNonZeroIndexes <- function(cutp) {
out <- c()
outIndex <- 1
zeroRow <- list(numeric(0))
for (i in 1:length(cutp)) {
l <- cutp[i]
if (!identical(l, zeroRow)) {
out[outIndex] <- i
outIndex <- outIndex + 1
}
}
return(out)
}
validIndexes <- getNonZeroIndexes(DISC$cutp)
#xs <- xs[, validIndexes]
#DISC$cutp = DISC$cutp[validIndexes]
# discretize TEST
xsd <- sapply(1:ncol(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
# predict LRARs
yp <- crank(rulz, xsd, ys, std, m2, 1)#mt)
# evaluate predictions
tau <- mean(sapply(1:nrow(ys), function(j) cor(ys[j,], yp[,j], method="kendall")))
tau
# load dependencies
require("carenR")
source("LRAR/caren.R")
source("LRAR/predictLRAR.R")
source("edira/edira.R")
# read DATA
## PT
out <- read.csv("../data/out_german_based.csv", sep = ";", stringsAsFactors=FALSE, fileEncoding="latin1")
## GET
#out <- read.csv("../data/out_german.csv", sep = ";", stringsAsFactors=FALSE, fileEncoding="latin1")
# transform DATA
## select rows of relevant parties
### PT
rankings <- out[,c(3,4,11,15,29)]
### GER
#rankings <- out[,c(33:37)]
## split in independent variables (x) and votes (y)
### PT
y <- t(apply(-rankings, 1, rank))
x <- out[,-c(0:33)]
### GER
#y <- t(apply(rankings, 1, rank))
#x <- out[,c(4:32)]
## transform dataframes in matrixes
x <- as.matrix(x)
y <- as.matrix(y)
## sample size percentage for TRAIN
smp_size <- floor(0.75 * nrow(x))
## set the seed to make the partition reproductible
set.seed(123)
## split
train_ind <- sample(seq_len(nrow(x)), size = smp_size)
x <- x[train_ind, ]
xs <- x[-train_ind, ]
y <- y[train_ind, ]
ys <- y[-train_ind, ]
# discretize TRAIN
DISC <- mdlp.rank(x, y, method = "kendall")
xd = DISC$Disc.data
# mine LR rules
rulz <- aflrC7(xd, y, msup = 1, mconf = 70, mlift = 0, mimp = 0, theta = 0, Xmx = "2000M")
getNonZeroIndexes <- function(cutp) {
out <- c()
outIndex <- 1
zeroRow <- list(numeric(0))
for (i in 1:length(cutp)) {
l <- cutp[i]
if (!identical(l, zeroRow)) {
out[outIndex] <- i
outIndex <- outIndex + 1
}
}
return(out)
}
validIndexes <- getNonZeroIndexes(DISC$cutp)
#xs <- xs[, validIndexes]
#DISC$cutp = DISC$cutp[validIndexes]
# discretize TEST
xsd <- sapply(1:ncol(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
# predict LRARs
yp <- crank(rulz, xsd, ys, std, m2, 1)#mt)
# evaluate predictions
tau <- mean(sapply(1:nrow(ys), function(j) cor(ys[j,], yp[,j], method="kendall")))
tau
# load dependencies
require("carenR")
source("LRAR/caren.R")
source("LRAR/predictLRAR.R")
source("edira/edira.R")
# read DATA
## PT
out <- read.csv("../data/out_german_based_charfix.csv", sep = ";", stringsAsFactors=FALSE, fileEncoding="latin1")
## GET
#out <- read.csv("../data/out_german.csv", sep = ";", stringsAsFactors=FALSE, fileEncoding="latin1")
# transform DATA
## select rows of relevant parties
### PT
rankings <- out[,c(3,4,11,15,29)]
### GER
#rankings <- out[,c(33:37)]
## split in independent variables (x) and votes (y)
### PT
y <- t(apply(-rankings, 1, rank))
x <- out[,-c(0:33)]
### GER
#y <- t(apply(rankings, 1, rank))
#x <- out[,c(4:32)]
## transform dataframes in matrixes
x <- as.matrix(x)
y <- as.matrix(y)
## sample size percentage for TRAIN
smp_size <- floor(0.75 * nrow(x))
## set the seed to make the partition reproductible
set.seed(123)
## split
train_ind <- sample(seq_len(nrow(x)), size = smp_size)
x <- x[train_ind, ]
xs <- x[-train_ind, ]
y <- y[train_ind, ]
ys <- y[-train_ind, ]
# discretize TRAIN
DISC <- mdlp.rank(x, y, method = "kendall")
xd = DISC$Disc.data
# mine LR rules
rulz <- aflrC7(xd, y, msup = 1, mconf = 70, mlift = 0, mimp = 0, theta = 0, Xmx = "2000M")
getNonZeroIndexes <- function(cutp) {
out <- c()
outIndex <- 1
zeroRow <- list(numeric(0))
for (i in 1:length(cutp)) {
l <- cutp[i]
if (!identical(l, zeroRow)) {
out[outIndex] <- i
outIndex <- outIndex + 1
}
}
return(out)
}
validIndexes <- getNonZeroIndexes(DISC$cutp)
#xs <- xs[, validIndexes]
#DISC$cutp = DISC$cutp[validIndexes]
# discretize TEST
xsd <- sapply(1:ncol(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
# predict LRARs
yp <- crank(rulz, xsd, ys, std, m2, 1)#mt)
# evaluate predictions
tau <- mean(sapply(1:nrow(ys), function(j) cor(ys[j,], yp[,j], method="kendall")))
tau
out <- read.csv("../data/out_german_based_charfix.csv", sep = ";", stringsAsFactors=FALSE, fileEncoding="latin1")
# load dependencies
require("carenR")
source("LRAR/caren.R")
source("LRAR/predictLRAR.R")
source("edira/edira.R")
# read DATA
## PT
out <- read.csv("../data/out_german_based_charfix.csv", sep = ";", stringsAsFactors=FALSE, fileEncoding="latin1")
## GET
#out <- read.csv("../data/out_german.csv", sep = ";", stringsAsFactors=FALSE, fileEncoding="latin1")
# transform DATA
## select rows of relevant parties
### PT
rankings <- out[,c(3,4,11,15,29)]
### GER
#rankings <- out[,c(33:37)]
## split in independent variables (x) and votes (y)
### PT
y <- t(apply(-rankings, 1, rank))
x <- out[,-c(0:33)]
### GER
#y <- t(apply(rankings, 1, rank))
#x <- out[,c(4:32)]
## transform dataframes in matrixes
x <- as.matrix(x)
y <- as.matrix(y)
## sample size percentage for TRAIN
smp_size <- floor(0.75 * nrow(x))
## set the seed to make the partition reproductible
set.seed(123)
## split
train_ind <- sample(seq_len(nrow(x)), size = smp_size)
x <- x[train_ind, ]
xs <- x[-train_ind, ]
y <- y[train_ind, ]
ys <- y[-train_ind, ]
# discretize TRAIN
DISC <- mdlp.rank(x, y, method = "kendall")
xd = DISC$Disc.data
# mine LR rules
rulz <- aflrC7(xd, y, msup = 1, mconf = 70, mlift = 0, mimp = 0, theta = 0, Xmx = "2000M")
getNonZeroIndexes <- function(cutp) {
out <- c()
outIndex <- 1
zeroRow <- list(numeric(0))
for (i in 1:length(cutp)) {
l <- cutp[i]
if (!identical(l, zeroRow)) {
out[outIndex] <- i
outIndex <- outIndex + 1
}
}
return(out)
}
validIndexes <- getNonZeroIndexes(DISC$cutp)
#xs <- xs[, validIndexes]
#DISC$cutp = DISC$cutp[validIndexes]
# discretize TEST
xsd <- sapply(1:ncol(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
# predict LRARs
yp <- crank(rulz, xsd, ys, std, m2, 1)#mt)
# evaluate predictions
tau <- mean(sapply(1:nrow(ys), function(j) cor(ys[j,], yp[,j], method="kendall")))
tau
# load dependencies
require("carenR")
source("LRAR/caren.R")
source("LRAR/predictLRAR.R")
source("edira/edira.R")
# read DATA
## PT
out <- read.csv("../data/out_german_based_charfix.csv", sep = ";", stringsAsFactors=FALSE, fileEncoding="latin1")
## GET
#out <- read.csv("../data/out_german.csv", sep = ";", stringsAsFactors=FALSE, fileEncoding="latin1")
# transform DATA
## select rows of relevant parties
### PT
rankings <- out[,c(3,4,11,15,29)]
### GER
#rankings <- out[,c(33:37)]
## split in independent variables (x) and votes (y)
### PT
y <- t(apply(-rankings, 1, rank))
x <- out[,-c(0:33)]
### GER
#y <- t(apply(rankings, 1, rank))
#x <- out[,c(4:32)]
## transform dataframes in matrixes
x <- as.matrix(x)
y <- as.matrix(y)
## sample size percentage for TRAIN
smp_size <- floor(0.75 * nrow(x))
## set the seed to make the partition reproductible
set.seed(123)
## split
train_ind <- sample(seq_len(nrow(x)), size = smp_size)
x <- x[train_ind, ]
xs <- x[-train_ind, ]
y <- y[train_ind, ]
ys <- y[-train_ind, ]
# discretize TRAIN
DISC <- mdlp.rank(x, y, method = "kendall")
xd = DISC$Disc.data
# mine LR rules
rulz <- aflrC7(xd, y, msup = 1, mconf = 70, mlift = 0, mimp = 0, theta = 0, Xmx = "2000M")
getNonZeroIndexes <- function(cutp) {
out <- c()
outIndex <- 1
zeroRow <- list(numeric(0))
for (i in 1:length(cutp)) {
l <- cutp[i]
if (!identical(l, zeroRow)) {
out[outIndex] <- i
outIndex <- outIndex + 1
}
}
return(out)
}
validIndexes <- getNonZeroIndexes(DISC$cutp)
#xs <- xs[, validIndexes]
#DISC$cutp = DISC$cutp[validIndexes]
# discretize TEST
xsd <- sapply(1:ncol(xs), function(j){
findInterval(xs[,j], c(-Inf, DISC$cutp[[j]], Inf))
})
# predict LRARs
yp <- crank(rulz, xsd, ys, std, m2, 1)#mt)
# evaluate predictions
tau <- mean(sapply(1:nrow(ys), function(j) cor(ys[j,], yp[,j], method="kendall")))
tau
help("carenR")
View(aflrC7)
